{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Title'] = data['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n",
    "data['GivenName'] = data['Name'].str.split(',').str[1].str.split('.').str[1].str.split('\\(')\\\n",
    "                     .str[0].str.strip()\n",
    "data['FamilyName'] = data['Name'].str.split(',').str[0].str.strip()\n",
    "\n",
    "def process_title(original_title):\n",
    "    title_dictionary = {\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"the Countess\":\"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\"\n",
    "                    }\n",
    "    return title_dictionary.get(original_title) or 'Unknown'\n",
    "\n",
    "data.Title = np.vectorize(process_title)(data.Title)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling age by title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGE_TITLE_MAPPING = data.groupby(['Title'])['Age'].median().reset_index(name=\"age_med\").to_dict()\n",
    "AGE_TITLE_MAPPING['Unknown']=29\n",
    "\n",
    "def process_age(age_val, title_val):\n",
    "    res = age_val\n",
    "    if math.isnan(res):\n",
    "        res = AGE_TITLE_MAPPING.get(title_val) or AGE_TITLE_MAPPING.get(\"Unknown\")\n",
    "    return res\n",
    "\n",
    "data.Age = np.vectorize(process_age)(data.Age, data.Title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lab/27py/lib/python2.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>GivenName</th>\n",
       "      <th>FamilyName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Icard, Miss. Amelie</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Amelie</td>\n",
       "      <td>Icard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Stone, Mrs. George Nelson (Martha Evelyn)</td>\n",
       "      <td>female</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113572</td>\n",
       "      <td>80.0</td>\n",
       "      <td>B28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>George Nelson</td>\n",
       "      <td>Stone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                       Name  \\\n",
       "61            62         1       1                        Icard, Miss. Amelie   \n",
       "829          830         1       1  Stone, Mrs. George Nelson (Martha Evelyn)   \n",
       "\n",
       "        Sex   Age  SibSp  Parch  Ticket  Fare Cabin Embarked Title  \\\n",
       "61   female  38.0      0      0  113572  80.0   B28      NaN  Miss   \n",
       "829  female  62.0      0      0  113572  80.0   B28      NaN   Mrs   \n",
       "\n",
       "         GivenName FamilyName  \n",
       "61          Amelie      Icard  \n",
       "829  George Nelson      Stone  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Embarked != 'S'][data.Embarked != 'Q'][data.Embarked != 'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass  Embarked\n",
       "1       C            85\n",
       "        Q             2\n",
       "        S           127\n",
       "2       C            17\n",
       "        Q             3\n",
       "        S           164\n",
       "3       C            66\n",
       "        Q            72\n",
       "        S           353\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Pclass','Embarked']).count().PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embarked at 'S' is the most in every class\n",
    "data.Embarked.fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_cabin(cabin_num):\n",
    "#     print cabin_num\n",
    "    return 'Yes' if str(cabin_num) != 'nan' else 'No'\n",
    "\n",
    "data['HasCabinNum'] = np.vectorize(check_cabin)(data.Cabin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>GivenName</th>\n",
       "      <th>FamilyName</th>\n",
       "      <th>HasCabinNum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>Braund</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>John Bradley</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Laina</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Jacques Heath</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>Allen</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked Title      GivenName  \\\n",
       "0      0         A/5 21171   7.2500   NaN        S    Mr    Owen Harris   \n",
       "1      0          PC 17599  71.2833   C85        C   Mrs   John Bradley   \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  Miss          Laina   \n",
       "3      0            113803  53.1000  C123        S   Mrs  Jacques Heath   \n",
       "4      0            373450   8.0500   NaN        S    Mr  William Henry   \n",
       "\n",
       "  FamilyName HasCabinNum  \n",
       "0     Braund          No  \n",
       "1    Cumings         Yes  \n",
       "2  Heikkinen          No  \n",
       "3   Futrelle         Yes  \n",
       "4      Allen          No  "
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_physical(age_val):\n",
    "    res = ''\n",
    "    if age_val >= 16:\n",
    "        if age_val >= 60:\n",
    "            res = 'Old_Man'\n",
    "        else:\n",
    "            res = 'Adult'\n",
    "    else:\n",
    "        res = 'Child'    \n",
    "    return  res\n",
    "\n",
    "data['Physical'] = np.vectorize(check_physical)(data.Age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Royal class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class(title_val):\n",
    "#     print cabin_num\n",
    "    return 'Noble' if title_val == 'Royalty' else 'Civilian'\n",
    "\n",
    "data['Class'] = np.vectorize(check_class)(data.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       891 non-null object\n",
      "Title          891 non-null object\n",
      "GivenName      891 non-null object\n",
      "FamilyName     891 non-null object\n",
      "HasCabinNum    891 non-null object\n",
      "Physical       891 non-null object\n",
      "Class          891 non-null object\n",
      "dtypes: float64(2), int64(5), object(11)\n",
      "memory usage: 125.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>HasCabinNum</th>\n",
       "      <th>Physical</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>No</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Civilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Civilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "      <td>No</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Civilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Civilian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "      <td>No</td>\n",
       "      <td>Adult</td>\n",
       "      <td>Civilian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S    Mr   \n",
       "1         1       1  female  38.0      1      0  71.2833        C   Mrs   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Miss   \n",
       "3         1       1  female  35.0      1      0  53.1000        S   Mrs   \n",
       "4         0       3    male  35.0      0      0   8.0500        S    Mr   \n",
       "\n",
       "  HasCabinNum Physical     Class  \n",
       "0          No    Adult  Civilian  \n",
       "1         Yes    Adult  Civilian  \n",
       "2          No    Adult  Civilian  \n",
       "3         Yes    Adult  Civilian  \n",
       "4          No    Adult  Civilian  "
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_col = data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'GivenName', 'FamilyName'], axis=1)\n",
    "target_col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 26 columns):\n",
      "Survived            891 non-null int64\n",
      "Age                 891 non-null float64\n",
      "SibSp               891 non-null int64\n",
      "Parch               891 non-null int64\n",
      "Fare                891 non-null float64\n",
      "Physical_Adult      891 non-null uint8\n",
      "Physical_Child      891 non-null uint8\n",
      "Physical_Old_Man    891 non-null uint8\n",
      "Class_Civilian      891 non-null uint8\n",
      "Class_Noble         891 non-null uint8\n",
      "Title_Master        891 non-null uint8\n",
      "Title_Miss          891 non-null uint8\n",
      "Title_Mr            891 non-null uint8\n",
      "Title_Mrs           891 non-null uint8\n",
      "Title_Officer       891 non-null uint8\n",
      "Title_Royalty       891 non-null uint8\n",
      "Cabin_No            891 non-null uint8\n",
      "Cabin_Yes           891 non-null uint8\n",
      "Embarked_C          891 non-null uint8\n",
      "Embarked_Q          891 non-null uint8\n",
      "Embarked_S          891 non-null uint8\n",
      "Sex_female          891 non-null uint8\n",
      "Sex_male            891 non-null uint8\n",
      "Pclass_1            891 non-null uint8\n",
      "Pclass_2            891 non-null uint8\n",
      "Pclass_3            891 non-null uint8\n",
      "dtypes: float64(2), int64(3), uint8(21)\n",
      "memory usage: 53.1 KB\n"
     ]
    }
   ],
   "source": [
    "dummies_Class = pd.get_dummies(target_col['Class'], prefix= 'Class')\n",
    "dummies_Physical = pd.get_dummies(target_col['Physical'], prefix= 'Physical')\n",
    "dummies_Title = pd.get_dummies(target_col['Title'], prefix= 'Title')\n",
    "dummies_Cabin = pd.get_dummies(target_col['HasCabinNum'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(target_col['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(target_col['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(target_col['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "df = pd.concat([target_col, dummies_Physical,dummies_Class, dummies_Title, dummies_Cabin, dummies_Embarked,\\\n",
    "                dummies_Sex, dummies_Pclass], axis=1)\n",
    "\n",
    "df.drop(['Pclass', 'Sex','HasCabinNum', 'Embarked', 'Title', 'HasCabinNum',\\\n",
    "        'Physical', 'Class' ], axis=1, inplace=True)\n",
    "\n",
    "df.info()\n",
    "# print df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Physical_Adult</th>\n",
       "      <th>Physical_Child</th>\n",
       "      <th>Physical_Old_Man</th>\n",
       "      <th>Class_Civilian</th>\n",
       "      <th>Class_Noble</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age  SibSp  Parch     Fare  Physical_Adult  Physical_Child  \\\n",
       "0         0  22.0      1      0   7.2500               1               0   \n",
       "1         1  38.0      1      0  71.2833               1               0   \n",
       "2         1  26.0      0      0   7.9250               1               0   \n",
       "\n",
       "   Physical_Old_Man  Class_Civilian  Class_Noble  Title_Master  Title_Miss  \\\n",
       "0                 0               1            0             0           0   \n",
       "1                 0               1            0             0           0   \n",
       "2                 0               1            0             0           1   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Officer  Title_Royalty  Cabin_No  Cabin_Yes  \\\n",
       "0         1          0              0              0         1          0   \n",
       "1         0          1              0              0         0          1   \n",
       "2         0          0              0              0         1          0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  Pclass_1  \\\n",
       "0           0           0           1           0         1         0   \n",
       "1           1           0           0           1         0         1   \n",
       "2           0           0           1           1         0         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  \n",
       "0         0         1  \n",
       "1         0         0  \n",
       "2         0         1  "
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[['Age', 'Fare', 'SibSp', 'Parch']] = scaler.fit_transform(df[['Age', 'Fare', 'SibSp', 'Parch']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Physical_Adult</th>\n",
       "      <th>Physical_Child</th>\n",
       "      <th>Physical_Old_Man</th>\n",
       "      <th>Class_Civilian</th>\n",
       "      <th>Class_Noble</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived       Age  SibSp  Parch      Fare  Physical_Adult  Physical_Child  \\\n",
       "0         0  0.271174  0.125    0.0  0.014151               1               0   \n",
       "1         1  0.472229  0.125    0.0  0.139136               1               0   \n",
       "2         1  0.321438  0.000    0.0  0.015469               1               0   \n",
       "3         1  0.434531  0.125    0.0  0.103644               1               0   \n",
       "4         0  0.434531  0.000    0.0  0.015713               1               0   \n",
       "\n",
       "   Physical_Old_Man  Class_Civilian  Class_Noble  Title_Master  Title_Miss  \\\n",
       "0                 0               1            0             0           0   \n",
       "1                 0               1            0             0           0   \n",
       "2                 0               1            0             0           1   \n",
       "3                 0               1            0             0           0   \n",
       "4                 0               1            0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Officer  Title_Royalty  Cabin_No  Cabin_Yes  \\\n",
       "0         1          0              0              0         1          0   \n",
       "1         0          1              0              0         0          1   \n",
       "2         0          0              0              0         1          0   \n",
       "3         0          1              0              0         0          1   \n",
       "4         1          0              0              0         1          0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  Pclass_1  \\\n",
       "0           0           0           1           0         1         0   \n",
       "1           1           0           0           1         0         1   \n",
       "2           0           0           1           1         0         0   \n",
       "3           0           0           1           1         0         1   \n",
       "4           0           0           1           0         1         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  \n",
       "0         0         1  \n",
       "1         0         0  \n",
       "2         0         1  \n",
       "3         0         0  \n",
       "4         0         1  "
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)\n",
    "# df.values[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD8CAYAAAB6paOMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c70f25110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "df_reduce = PCA(n_components=2).fit_transform(df.values[:,1:])\n",
    "df_reduce\n",
    "\n",
    "plt.scatter(df_reduce[:,0],df_reduce[:,1], c=df.values[:,0])\n",
    "plt.show()\n",
    "# # df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.93563448, -0.21405666],\n",
       "       [ 1.75080014,  1.01894103],\n",
       "       [ 0.75519858, -1.08608193],\n",
       "       ..., \n",
       "       [ 0.77095083, -1.09431244],\n",
       "       [ 0.13960428,  1.72359588],\n",
       "       [-0.82275984, -0.22614324]])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 179 points : 42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "df_train ,df_test = train_test_split(df,test_size=0.2)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "y_pred = mnb.fit(df_train.values[:,4:], df_train.values[:,0]).predict(df_test.values[:,4:])\n",
    "y_pred\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\\\n",
    "     % (df_test.values.shape[0],(df_test.values[:,0] != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1787709497206704"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32.0/179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/lab/27py/lib/python2.7/site-packages/ipykernel_launcher.py:10: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Physical_Adult</th>\n",
       "      <th>Physical_Child</th>\n",
       "      <th>Physical_Old_Man</th>\n",
       "      <th>Class_Civilian</th>\n",
       "      <th>Class_Noble</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Officer</th>\n",
       "      <th>Title_Royalty</th>\n",
       "      <th>Cabin_No</th>\n",
       "      <th>Cabin_Yes</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.452723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617566</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013663</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.815377</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353818</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287881</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  SibSp     Parch      Fare  Physical_Adult  Physical_Child  \\\n",
       "0  0.452723  0.000  0.000000  0.015282               1               0   \n",
       "1  0.617566  0.125  0.000000  0.013663               1               0   \n",
       "2  0.815377  0.000  0.000000  0.018909               0               0   \n",
       "3  0.353818  0.000  0.000000  0.016908               1               0   \n",
       "4  0.287881  0.125  0.111111  0.023984               1               0   \n",
       "\n",
       "   Physical_Old_Man  Class_Civilian  Class_Noble  Title_Master  Title_Miss  \\\n",
       "0                 0               1            0             0           0   \n",
       "1                 0               1            0             0           0   \n",
       "2                 1               1            0             0           0   \n",
       "3                 0               1            0             0           0   \n",
       "4                 0               1            0             0           0   \n",
       "\n",
       "   Title_Mr  Title_Mrs  Title_Officer  Title_Royalty  Cabin_No  Cabin_Yes  \\\n",
       "0         1          0              0              0         1          0   \n",
       "1         0          1              0              0         1          0   \n",
       "2         1          0              0              0         1          0   \n",
       "3         1          0              0              0         1          0   \n",
       "4         0          1              0              0         1          0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  Pclass_1  \\\n",
       "0           0           1           0           0         1         0   \n",
       "1           0           0           1           1         0         0   \n",
       "2           0           1           0           0         1         0   \n",
       "3           0           0           1           0         1         0   \n",
       "4           0           0           1           1         0         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  \n",
       "0         0         1  \n",
       "1         0         1  \n",
       "2         1         0  \n",
       "3         0         1  \n",
       "4         0         1  "
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('data/test.csv')\n",
    "# Fill some one is in Pclass 3 but Fare is NaN\n",
    "data_test['Fare'].fillna(8.0, inplace=True)\n",
    "data_test['Title'] = data_test['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n",
    "data_test['GivenName'] = data_test['Name'].str.split(',').str[1].str.split('.').str[1].str.split('\\(')\\\n",
    "                     .str[0].str.strip()\n",
    "data_test['FamilyName'] = data_test['Name'].str.split(',').str[0].str.strip()\n",
    "data_test.Title = np.vectorize(process_title)(data_test.Title)\n",
    "data_test.Age = np.vectorize(process_age)(data_test.Age, data_test.Title)\n",
    "\n",
    "data_test[data_test.Embarked != 'S'][data_test.Embarked != 'Q'][data_test.Embarked != 'C']\n",
    "data_test.Embarked.fillna('S', inplace=True)\n",
    "data_test['HasCabinNum'] = np.vectorize(check_cabin)(data_test.Cabin)\n",
    "\n",
    "data_test['Physical'] = np.vectorize(check_physical)(data_test.Age)\n",
    "\n",
    "data_test['Class'] = np.vectorize(check_class)(data_test.Title)\n",
    "target_test_col = data_test.drop(['PassengerId', 'Name', 'Ticket', 'Cabin', 'GivenName', 'FamilyName'], axis=1)\n",
    "dummies_Class = pd.get_dummies(target_test_col['Class'], prefix= 'Class')\n",
    "dummies_Physical = pd.get_dummies(target_test_col['Physical'], prefix= 'Physical')\n",
    "dummies_Title = pd.get_dummies(target_test_col['Title'], prefix= 'Title')\n",
    "dummies_Cabin = pd.get_dummies(target_test_col['HasCabinNum'], prefix= 'Cabin')\n",
    "dummies_Embarked = pd.get_dummies(target_test_col['Embarked'], prefix= 'Embarked')\n",
    "dummies_Sex = pd.get_dummies(target_test_col['Sex'], prefix= 'Sex')\n",
    "dummies_Pclass = pd.get_dummies(target_test_col['Pclass'], prefix= 'Pclass')\n",
    "\n",
    "df_test = pd.concat([target_test_col, dummies_Physical,dummies_Class, dummies_Title, dummies_Cabin, dummies_Embarked,\\\n",
    "                dummies_Sex, dummies_Pclass], axis=1)\n",
    "\n",
    "df_test.drop(['Pclass', 'Sex','HasCabinNum', 'Embarked', 'Title', 'HasCabinNum',\\\n",
    "        'Physical', 'Class' ], axis=1, inplace=True)\n",
    "scaler = MinMaxScaler()\n",
    "df_test[['Age', 'Fare', 'SibSp', 'Parch']] = scaler.fit_transform(df_test[['Age', 'Fare', 'SibSp', 'Parch']])\n",
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,  1.,  0.,\n",
       "        1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
       "        0.,  0.,  1.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,\n",
       "        1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  0.,\n",
       "        0.,  1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "        0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,\n",
       "        0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,  1.,  0.,\n",
       "        1.,  1.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  0.,  1.,  1.,  1.,\n",
       "        0.,  0.,  0.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  1.,\n",
       "        1.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  1.,  0.,  1.,\n",
       "        0.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,\n",
       "        0.,  1.])"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "predictions = gnb.fit(df.values[:,1:], df.values[:,0]).predict(df_test.values)\n",
    "predictions\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':predictions.astype(np.int32)})\n",
    "# result.to_csv(\"/root/lab/27py/ipynb/titanic/data/naive_bayesian_GaussianNB_predictions.csv\", index=False)\n",
    "# 76.5% using Naive Bayes no matter it's Gaussian or Multinomial\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 25 columns):\n",
      "Age                 418 non-null float64\n",
      "SibSp               418 non-null float64\n",
      "Parch               418 non-null float64\n",
      "Fare                418 non-null float64\n",
      "Physical_Adult      418 non-null uint8\n",
      "Physical_Child      418 non-null uint8\n",
      "Physical_Old_Man    418 non-null uint8\n",
      "Class_Civilian      418 non-null uint8\n",
      "Class_Noble         418 non-null uint8\n",
      "Title_Master        418 non-null uint8\n",
      "Title_Miss          418 non-null uint8\n",
      "Title_Mr            418 non-null uint8\n",
      "Title_Mrs           418 non-null uint8\n",
      "Title_Officer       418 non-null uint8\n",
      "Title_Royalty       418 non-null uint8\n",
      "Cabin_No            418 non-null uint8\n",
      "Cabin_Yes           418 non-null uint8\n",
      "Embarked_C          418 non-null uint8\n",
      "Embarked_Q          418 non-null uint8\n",
      "Embarked_S          418 non-null uint8\n",
      "Sex_female          418 non-null uint8\n",
      "Sex_male            418 non-null uint8\n",
      "Pclass_1            418 non-null uint8\n",
      "Pclass_2            418 non-null uint8\n",
      "Pclass_3            418 non-null uint8\n",
      "dtypes: float64(4), uint8(21)\n",
      "memory usage: 21.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 846 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "1s - loss: 0.5354 - acc: 0.7506 - val_loss: 0.3965 - val_acc: 0.8222\n",
      "Epoch 2/100\n",
      "0s - loss: 0.4537 - acc: 0.8085 - val_loss: 0.3197 - val_acc: 0.9111\n",
      "Epoch 3/100\n",
      "0s - loss: 0.4139 - acc: 0.8286 - val_loss: 0.2979 - val_acc: 0.8444\n",
      "Epoch 4/100\n",
      "0s - loss: 0.4106 - acc: 0.8274 - val_loss: 0.2810 - val_acc: 0.8889\n",
      "Epoch 5/100\n",
      "0s - loss: 0.4112 - acc: 0.8298 - val_loss: 0.2610 - val_acc: 0.8889\n",
      "Epoch 6/100\n",
      "0s - loss: 0.4079 - acc: 0.8298 - val_loss: 0.3945 - val_acc: 0.8667\n",
      "Epoch 7/100\n",
      "0s - loss: 0.4146 - acc: 0.8286 - val_loss: 0.2770 - val_acc: 0.8667\n",
      "Epoch 8/100\n",
      "0s - loss: 0.4009 - acc: 0.8369 - val_loss: 0.3013 - val_acc: 0.8889\n",
      "Epoch 9/100\n",
      "0s - loss: 0.3948 - acc: 0.8357 - val_loss: 0.2879 - val_acc: 0.8667\n",
      "Epoch 10/100\n",
      "0s - loss: 0.3973 - acc: 0.8286 - val_loss: 0.3345 - val_acc: 0.8889\n",
      "Epoch 11/100\n",
      "0s - loss: 0.3975 - acc: 0.8357 - val_loss: 0.3792 - val_acc: 0.8889\n",
      "Epoch 12/100\n",
      "0s - loss: 0.4130 - acc: 0.8392 - val_loss: 0.2786 - val_acc: 0.8889\n",
      "Epoch 13/100\n",
      "0s - loss: 0.4042 - acc: 0.8357 - val_loss: 0.2804 - val_acc: 0.8889\n",
      "Epoch 14/100\n",
      "0s - loss: 0.3981 - acc: 0.8310 - val_loss: 0.2994 - val_acc: 0.9111\n",
      "Epoch 15/100\n",
      "0s - loss: 0.3946 - acc: 0.8392 - val_loss: 0.2667 - val_acc: 0.8889\n",
      "Epoch 16/100\n",
      "0s - loss: 0.3907 - acc: 0.8392 - val_loss: 0.3109 - val_acc: 0.8889\n",
      "Epoch 17/100\n",
      "0s - loss: 0.3928 - acc: 0.8416 - val_loss: 0.2924 - val_acc: 0.8889\n",
      "Epoch 18/100\n",
      "0s - loss: 0.3888 - acc: 0.8404 - val_loss: 0.2665 - val_acc: 0.8889\n",
      "Epoch 19/100\n",
      "0s - loss: 0.3880 - acc: 0.8452 - val_loss: 0.2870 - val_acc: 0.9111\n",
      "Epoch 20/100\n",
      "0s - loss: 0.3889 - acc: 0.8440 - val_loss: 0.3133 - val_acc: 0.8667\n",
      "Epoch 21/100\n",
      "0s - loss: 0.3839 - acc: 0.8416 - val_loss: 0.2868 - val_acc: 0.8889\n",
      "Epoch 22/100\n",
      "0s - loss: 0.3932 - acc: 0.8369 - val_loss: 0.3010 - val_acc: 0.9111\n",
      "Epoch 23/100\n",
      "0s - loss: 0.3834 - acc: 0.8428 - val_loss: 0.2640 - val_acc: 0.8889\n",
      "Epoch 24/100\n",
      "0s - loss: 0.3863 - acc: 0.8463 - val_loss: 0.2900 - val_acc: 0.9111\n",
      "Epoch 25/100\n",
      "0s - loss: 0.3809 - acc: 0.8440 - val_loss: 0.2674 - val_acc: 0.8889\n",
      "Epoch 26/100\n",
      "0s - loss: 0.3845 - acc: 0.8440 - val_loss: 0.2774 - val_acc: 0.9111\n",
      "Epoch 27/100\n",
      "0s - loss: 0.3845 - acc: 0.8452 - val_loss: 0.2902 - val_acc: 0.8889\n",
      "Epoch 28/100\n",
      "0s - loss: 0.3939 - acc: 0.8381 - val_loss: 0.3106 - val_acc: 0.8667\n",
      "Epoch 29/100\n",
      "0s - loss: 0.3909 - acc: 0.8392 - val_loss: 0.2705 - val_acc: 0.8889\n",
      "Epoch 30/100\n",
      "0s - loss: 0.3841 - acc: 0.8428 - val_loss: 0.2759 - val_acc: 0.8889\n",
      "Epoch 31/100\n",
      "0s - loss: 0.3725 - acc: 0.8475 - val_loss: 0.3044 - val_acc: 0.9111\n",
      "Epoch 32/100\n",
      "0s - loss: 0.3762 - acc: 0.8416 - val_loss: 0.2848 - val_acc: 0.9111\n",
      "Epoch 33/100\n",
      "0s - loss: 0.3795 - acc: 0.8499 - val_loss: 0.3176 - val_acc: 0.9111\n",
      "Epoch 34/100\n",
      "0s - loss: 0.3788 - acc: 0.8428 - val_loss: 0.2939 - val_acc: 0.8889\n",
      "Epoch 35/100\n",
      "0s - loss: 0.3744 - acc: 0.8475 - val_loss: 0.2869 - val_acc: 0.8667\n",
      "Epoch 36/100\n",
      "0s - loss: 0.3782 - acc: 0.8475 - val_loss: 0.2829 - val_acc: 0.8889\n",
      "Epoch 37/100\n",
      "0s - loss: 0.3775 - acc: 0.8463 - val_loss: 0.2621 - val_acc: 0.8889\n",
      "Epoch 38/100\n",
      "0s - loss: 0.3804 - acc: 0.8369 - val_loss: 0.2857 - val_acc: 0.8889\n",
      "Epoch 39/100\n",
      "0s - loss: 0.3870 - acc: 0.8404 - val_loss: 0.2985 - val_acc: 0.8889\n",
      "Epoch 40/100\n",
      "0s - loss: 0.3778 - acc: 0.8392 - val_loss: 0.2702 - val_acc: 0.8889\n",
      "Epoch 41/100\n",
      "0s - loss: 0.3787 - acc: 0.8463 - val_loss: 0.2588 - val_acc: 0.8889\n",
      "Epoch 42/100\n",
      "0s - loss: 0.3713 - acc: 0.8487 - val_loss: 0.2851 - val_acc: 0.8889\n",
      "Epoch 43/100\n",
      "0s - loss: 0.3751 - acc: 0.8522 - val_loss: 0.2714 - val_acc: 0.8889\n",
      "Epoch 44/100\n",
      "0s - loss: 0.3729 - acc: 0.8499 - val_loss: 0.2800 - val_acc: 0.9111\n",
      "Epoch 45/100\n",
      "0s - loss: 0.3716 - acc: 0.8511 - val_loss: 0.2697 - val_acc: 0.9111\n",
      "Epoch 46/100\n",
      "0s - loss: 0.3702 - acc: 0.8475 - val_loss: 0.3025 - val_acc: 0.8889\n",
      "Epoch 47/100\n",
      "0s - loss: 0.3705 - acc: 0.8522 - val_loss: 0.2731 - val_acc: 0.8889\n",
      "Epoch 48/100\n",
      "0s - loss: 0.3685 - acc: 0.8511 - val_loss: 0.2661 - val_acc: 0.8889\n",
      "Epoch 49/100\n",
      "0s - loss: 0.3701 - acc: 0.8463 - val_loss: 0.2729 - val_acc: 0.9111\n",
      "Epoch 50/100\n",
      "0s - loss: 0.3713 - acc: 0.8463 - val_loss: 0.2817 - val_acc: 0.8889\n",
      "Epoch 51/100\n",
      "0s - loss: 0.3704 - acc: 0.8463 - val_loss: 0.2774 - val_acc: 0.9111\n",
      "Epoch 52/100\n",
      "0s - loss: 0.3706 - acc: 0.8428 - val_loss: 0.2659 - val_acc: 0.9111\n",
      "Epoch 53/100\n",
      "0s - loss: 0.3692 - acc: 0.8428 - val_loss: 0.2775 - val_acc: 0.9111\n",
      "Epoch 54/100\n",
      "0s - loss: 0.3675 - acc: 0.8452 - val_loss: 0.2738 - val_acc: 0.9111\n",
      "Epoch 55/100\n",
      "0s - loss: 0.3652 - acc: 0.8487 - val_loss: 0.2905 - val_acc: 0.9111\n",
      "Epoch 56/100\n",
      "0s - loss: 0.3672 - acc: 0.8475 - val_loss: 0.3019 - val_acc: 0.9333\n",
      "Epoch 57/100\n",
      "0s - loss: 0.3780 - acc: 0.8440 - val_loss: 0.3058 - val_acc: 0.8889\n",
      "Epoch 58/100\n",
      "0s - loss: 0.3665 - acc: 0.8475 - val_loss: 0.2865 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "0s - loss: 0.3635 - acc: 0.8452 - val_loss: 0.2809 - val_acc: 0.9111\n",
      "Epoch 60/100\n",
      "0s - loss: 0.3641 - acc: 0.8440 - val_loss: 0.3016 - val_acc: 0.9111\n",
      "Epoch 61/100\n",
      "0s - loss: 0.3638 - acc: 0.8522 - val_loss: 0.2920 - val_acc: 0.8889\n",
      "Epoch 62/100\n",
      "0s - loss: 0.3733 - acc: 0.8463 - val_loss: 0.3006 - val_acc: 0.9111\n",
      "Epoch 63/100\n",
      "0s - loss: 0.3643 - acc: 0.8475 - val_loss: 0.2728 - val_acc: 0.9111\n",
      "Epoch 64/100\n",
      "0s - loss: 0.3681 - acc: 0.8463 - val_loss: 0.2874 - val_acc: 0.8667\n",
      "Epoch 65/100\n",
      "0s - loss: 0.3653 - acc: 0.8511 - val_loss: 0.2817 - val_acc: 0.8889\n",
      "Epoch 66/100\n",
      "0s - loss: 0.3594 - acc: 0.8534 - val_loss: 0.2582 - val_acc: 0.9111\n",
      "Epoch 67/100\n",
      "0s - loss: 0.3738 - acc: 0.8475 - val_loss: 0.2393 - val_acc: 0.9111\n",
      "Epoch 68/100\n",
      "0s - loss: 0.3594 - acc: 0.8511 - val_loss: 0.2566 - val_acc: 0.8667\n",
      "Epoch 69/100\n",
      "0s - loss: 0.3618 - acc: 0.8475 - val_loss: 0.2588 - val_acc: 0.9111\n",
      "Epoch 70/100\n",
      "0s - loss: 0.3589 - acc: 0.8511 - val_loss: 0.2608 - val_acc: 0.9111\n",
      "Epoch 71/100\n",
      "0s - loss: 0.3613 - acc: 0.8558 - val_loss: 0.2760 - val_acc: 0.9111\n",
      "Epoch 72/100\n",
      "0s - loss: 0.3595 - acc: 0.8593 - val_loss: 0.2742 - val_acc: 0.8667\n",
      "Epoch 73/100\n",
      "0s - loss: 0.3631 - acc: 0.8463 - val_loss: 0.2546 - val_acc: 0.8889\n",
      "Epoch 74/100\n",
      "0s - loss: 0.3646 - acc: 0.8475 - val_loss: 0.2662 - val_acc: 0.9111\n",
      "Epoch 75/100\n",
      "0s - loss: 0.3634 - acc: 0.8487 - val_loss: 0.2836 - val_acc: 0.9111\n",
      "Epoch 76/100\n",
      "0s - loss: 0.3572 - acc: 0.8487 - val_loss: 0.2368 - val_acc: 0.8889\n",
      "Epoch 77/100\n",
      "0s - loss: 0.3693 - acc: 0.8499 - val_loss: 0.2716 - val_acc: 0.8667\n",
      "Epoch 78/100\n",
      "0s - loss: 0.3594 - acc: 0.8534 - val_loss: 0.2688 - val_acc: 0.9111\n",
      "Epoch 79/100\n",
      "0s - loss: 0.3695 - acc: 0.8463 - val_loss: 0.2746 - val_acc: 0.9111\n",
      "Epoch 80/100\n",
      "0s - loss: 0.3590 - acc: 0.8440 - val_loss: 0.2995 - val_acc: 0.9333\n",
      "Epoch 81/100\n",
      "0s - loss: 0.3570 - acc: 0.8522 - val_loss: 0.2765 - val_acc: 0.9333\n",
      "Epoch 82/100\n",
      "0s - loss: 0.3578 - acc: 0.8487 - val_loss: 0.3209 - val_acc: 0.9111\n",
      "Epoch 83/100\n",
      "0s - loss: 0.3629 - acc: 0.8475 - val_loss: 0.2868 - val_acc: 0.9333\n",
      "Epoch 84/100\n",
      "0s - loss: 0.3538 - acc: 0.8499 - val_loss: 0.2570 - val_acc: 0.8667\n",
      "Epoch 85/100\n",
      "0s - loss: 0.3523 - acc: 0.8511 - val_loss: 0.2546 - val_acc: 0.9333\n",
      "Epoch 86/100\n",
      "0s - loss: 0.3510 - acc: 0.8463 - val_loss: 0.2667 - val_acc: 0.8667\n",
      "Epoch 87/100\n",
      "0s - loss: 0.3553 - acc: 0.8475 - val_loss: 0.2777 - val_acc: 0.9111\n",
      "Epoch 88/100\n",
      "0s - loss: 0.3520 - acc: 0.8511 - val_loss: 0.2720 - val_acc: 0.8889\n",
      "Epoch 89/100\n",
      "0s - loss: 0.3519 - acc: 0.8546 - val_loss: 0.2725 - val_acc: 0.8222\n",
      "Epoch 90/100\n",
      "0s - loss: 0.3723 - acc: 0.8392 - val_loss: 0.2742 - val_acc: 0.9111\n",
      "Epoch 91/100\n",
      "0s - loss: 0.3611 - acc: 0.8440 - val_loss: 0.2889 - val_acc: 0.9333\n",
      "Epoch 92/100\n",
      "0s - loss: 0.3497 - acc: 0.8475 - val_loss: 0.2517 - val_acc: 0.9111\n",
      "Epoch 93/100\n",
      "0s - loss: 0.3534 - acc: 0.8511 - val_loss: 0.2632 - val_acc: 0.9333\n",
      "Epoch 94/100\n",
      "0s - loss: 0.3592 - acc: 0.8534 - val_loss: 0.2519 - val_acc: 0.9111\n",
      "Epoch 95/100\n",
      "0s - loss: 0.3517 - acc: 0.8499 - val_loss: 0.2562 - val_acc: 0.9111\n",
      "Epoch 96/100\n",
      "0s - loss: 0.3527 - acc: 0.8534 - val_loss: 0.2675 - val_acc: 0.9333\n",
      "Epoch 97/100\n",
      "0s - loss: 0.3429 - acc: 0.8534 - val_loss: 0.2950 - val_acc: 0.9111\n",
      "Epoch 98/100\n",
      "0s - loss: 0.3498 - acc: 0.8522 - val_loss: 0.2840 - val_acc: 0.9111\n",
      "Epoch 99/100\n",
      "0s - loss: 0.3527 - acc: 0.8463 - val_loss: 0.2653 - val_acc: 0.9333\n",
      "Epoch 100/100\n",
      "0s - loss: 0.3477 - acc: 0.8534 - val_loss: 0.2941 - val_acc: 0.9333\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "train_features = df.values[:,1:].copy()\n",
    "train_labels = df.values[:,0].copy()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=40, input_dim=25, kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dropout(rate=0.05))\n",
    "model.add(Dense(units=20, kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dropout(rate=0.05))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(x=train_features, \\\n",
    "                          y=train_labels, \\\n",
    "                          validation_split=0.05, \\\n",
    "                          epochs=100, \\\n",
    "                          batch_size=20, verbose=2)\n",
    "\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# show_train_history(train_history, 'acc', 'val_acc')\n",
    "# show_train_history(train_history, 'loss', 'val_loss')\n",
    "\n",
    "\n",
    "pred = model.predict_classes(df_test.values, verbose=2)\n",
    "# pred.ravel()\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':pred.ravel().astype(np.int32)})\n",
    "result\n",
    "result.to_csv(\"/root/lab/27py/ipynb/titanic/data/keras_mlp_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still 76~78% when drop some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt')\n",
    "clf = clf.fit(df.loc[:, df.columns != 'Survived'], df.Survived)\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Age', u'SibSp', u'Parch', u'Fare', u'Physical_Adult',\n",
       "       u'Physical_Child', u'Physical_Old_Man', u'Class_Civilian',\n",
       "       u'Class_Noble', u'Title_Master', u'Title_Miss', u'Title_Mr',\n",
       "       u'Title_Mrs', u'Title_Officer', u'Title_Royalty', u'Cabin_No',\n",
       "       u'Cabin_Yes', u'Embarked_C', u'Embarked_Q', u'Embarked_S',\n",
       "       u'Sex_female', u'Sex_male', u'Pclass_1', u'Pclass_2', u'Pclass_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, df.columns != 'Survived'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNsAAARiCAYAAACd0PFsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c70910f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = pd.DataFrame()\n",
    "features['feature'] = df.loc[:, df.columns != 'Survived'].columns\n",
    "features['importance'] = clf.feature_importances_\n",
    "features.sort_values(by=['importance'], ascending=True, inplace=True)\n",
    "features.set_index('feature', inplace=True)\n",
    "features.plot(kind='barh', figsize=(20, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 7)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = SelectFromModel(clf, prefit=True)\n",
    "train_reduced = rf_model.transform(df.loc[:, df.columns != 'Survived'])\n",
    "train_reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.4527232 ,  0.        ,  0.01528158, ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.61756561,  0.125     ,  0.01366309, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.8153765 ,  0.        ,  0.01890874, ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.50547277,  0.        ,  0.01415106, ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.38019254,  0.        ,  0.01571255, ...,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.38019254,  0.125     ,  0.0436405 , ...,  0.        ,\n",
       "         1.        ,  1.        ]])"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reduced = rf_model.transform(df_test)\n",
    "test_reduced.shape\n",
    "test_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 846 samples, validate on 45 samples\n",
      "Epoch 1/100\n",
      "1s - loss: 0.5800 - acc: 0.7009 - val_loss: 0.4513 - val_acc: 0.8000\n",
      "Epoch 2/100\n",
      "0s - loss: 0.4925 - acc: 0.7967 - val_loss: 0.3938 - val_acc: 0.8222\n",
      "Epoch 3/100\n",
      "0s - loss: 0.4740 - acc: 0.7991 - val_loss: 0.3921 - val_acc: 0.8000\n",
      "Epoch 4/100\n",
      "0s - loss: 0.4529 - acc: 0.8014 - val_loss: 0.3772 - val_acc: 0.8000\n",
      "Epoch 5/100\n",
      "0s - loss: 0.4404 - acc: 0.8073 - val_loss: 0.3911 - val_acc: 0.8000\n",
      "Epoch 6/100\n",
      "0s - loss: 0.4338 - acc: 0.7967 - val_loss: 0.3618 - val_acc: 0.8222\n",
      "Epoch 7/100\n",
      "0s - loss: 0.4354 - acc: 0.8109 - val_loss: 0.3832 - val_acc: 0.8222\n",
      "Epoch 8/100\n",
      "0s - loss: 0.4371 - acc: 0.8109 - val_loss: 0.3953 - val_acc: 0.7778\n",
      "Epoch 9/100\n",
      "0s - loss: 0.4330 - acc: 0.8085 - val_loss: 0.4025 - val_acc: 0.7778\n",
      "Epoch 10/100\n",
      "0s - loss: 0.4376 - acc: 0.8215 - val_loss: 0.3756 - val_acc: 0.8222\n",
      "Epoch 11/100\n",
      "0s - loss: 0.4356 - acc: 0.8144 - val_loss: 0.3613 - val_acc: 0.8222\n",
      "Epoch 12/100\n",
      "0s - loss: 0.4317 - acc: 0.8168 - val_loss: 0.3840 - val_acc: 0.8000\n",
      "Epoch 13/100\n",
      "0s - loss: 0.4268 - acc: 0.8180 - val_loss: 0.3543 - val_acc: 0.8444\n",
      "Epoch 14/100\n",
      "0s - loss: 0.4347 - acc: 0.8168 - val_loss: 0.3801 - val_acc: 0.7778\n",
      "Epoch 15/100\n",
      "0s - loss: 0.4293 - acc: 0.8097 - val_loss: 0.4159 - val_acc: 0.7778\n",
      "Epoch 16/100\n",
      "0s - loss: 0.4299 - acc: 0.8191 - val_loss: 0.3752 - val_acc: 0.8000\n",
      "Epoch 17/100\n",
      "0s - loss: 0.4329 - acc: 0.8227 - val_loss: 0.4029 - val_acc: 0.8000\n",
      "Epoch 18/100\n",
      "0s - loss: 0.4309 - acc: 0.8191 - val_loss: 0.3977 - val_acc: 0.8000\n",
      "Epoch 19/100\n",
      "0s - loss: 0.4268 - acc: 0.8251 - val_loss: 0.3877 - val_acc: 0.8222\n",
      "Epoch 20/100\n",
      "0s - loss: 0.4238 - acc: 0.8298 - val_loss: 0.3742 - val_acc: 0.8222\n",
      "Epoch 21/100\n",
      "0s - loss: 0.4212 - acc: 0.8215 - val_loss: 0.4293 - val_acc: 0.8000\n",
      "Epoch 22/100\n",
      "0s - loss: 0.4279 - acc: 0.8203 - val_loss: 0.3889 - val_acc: 0.8000\n",
      "Epoch 23/100\n",
      "0s - loss: 0.4356 - acc: 0.8274 - val_loss: 0.3679 - val_acc: 0.8000\n",
      "Epoch 24/100\n",
      "0s - loss: 0.4253 - acc: 0.8251 - val_loss: 0.3698 - val_acc: 0.8444\n",
      "Epoch 25/100\n",
      "0s - loss: 0.4163 - acc: 0.8286 - val_loss: 0.3293 - val_acc: 0.8889\n",
      "Epoch 26/100\n",
      "0s - loss: 0.4265 - acc: 0.8274 - val_loss: 0.3649 - val_acc: 0.8000\n",
      "Epoch 27/100\n",
      "0s - loss: 0.4226 - acc: 0.8215 - val_loss: 0.3737 - val_acc: 0.8000\n",
      "Epoch 28/100\n",
      "0s - loss: 0.4171 - acc: 0.8286 - val_loss: 0.3386 - val_acc: 0.8667\n",
      "Epoch 29/100\n",
      "0s - loss: 0.4249 - acc: 0.8227 - val_loss: 0.3674 - val_acc: 0.8222\n",
      "Epoch 30/100\n",
      "0s - loss: 0.4176 - acc: 0.8381 - val_loss: 0.3916 - val_acc: 0.8222\n",
      "Epoch 31/100\n",
      "0s - loss: 0.4325 - acc: 0.8215 - val_loss: 0.3879 - val_acc: 0.8000\n",
      "Epoch 32/100\n",
      "0s - loss: 0.4230 - acc: 0.8286 - val_loss: 0.3283 - val_acc: 0.8889\n",
      "Epoch 33/100\n",
      "0s - loss: 0.4187 - acc: 0.8239 - val_loss: 0.3507 - val_acc: 0.8222\n",
      "Epoch 34/100\n",
      "0s - loss: 0.4161 - acc: 0.8310 - val_loss: 0.3839 - val_acc: 0.8000\n",
      "Epoch 35/100\n",
      "0s - loss: 0.4242 - acc: 0.8274 - val_loss: 0.4469 - val_acc: 0.8000\n",
      "Epoch 36/100\n",
      "0s - loss: 0.4227 - acc: 0.8109 - val_loss: 0.3462 - val_acc: 0.8222\n",
      "Epoch 37/100\n",
      "0s - loss: 0.4122 - acc: 0.8215 - val_loss: 0.3411 - val_acc: 0.8889\n",
      "Epoch 38/100\n",
      "0s - loss: 0.4108 - acc: 0.8345 - val_loss: 0.3853 - val_acc: 0.8000\n",
      "Epoch 39/100\n",
      "0s - loss: 0.4121 - acc: 0.8310 - val_loss: 0.3361 - val_acc: 0.8889\n",
      "Epoch 40/100\n",
      "0s - loss: 0.4098 - acc: 0.8310 - val_loss: 0.3763 - val_acc: 0.8000\n",
      "Epoch 41/100\n",
      "0s - loss: 0.4130 - acc: 0.8298 - val_loss: 0.3679 - val_acc: 0.8222\n",
      "Epoch 42/100\n",
      "0s - loss: 0.4057 - acc: 0.8345 - val_loss: 0.3331 - val_acc: 0.8667\n",
      "Epoch 43/100\n",
      "0s - loss: 0.4273 - acc: 0.8203 - val_loss: 0.3353 - val_acc: 0.8889\n",
      "Epoch 44/100\n",
      "0s - loss: 0.4085 - acc: 0.8322 - val_loss: 0.3339 - val_acc: 0.8889\n",
      "Epoch 45/100\n",
      "0s - loss: 0.4025 - acc: 0.8298 - val_loss: 0.3249 - val_acc: 0.8889\n",
      "Epoch 46/100\n",
      "0s - loss: 0.4134 - acc: 0.8203 - val_loss: 0.3197 - val_acc: 0.8889\n",
      "Epoch 47/100\n",
      "0s - loss: 0.4151 - acc: 0.8298 - val_loss: 0.3265 - val_acc: 0.8889\n",
      "Epoch 48/100\n",
      "0s - loss: 0.4132 - acc: 0.8227 - val_loss: 0.3327 - val_acc: 0.8889\n",
      "Epoch 49/100\n",
      "0s - loss: 0.4103 - acc: 0.8345 - val_loss: 0.3714 - val_acc: 0.8444\n",
      "Epoch 50/100\n",
      "0s - loss: 0.4075 - acc: 0.8322 - val_loss: 0.3489 - val_acc: 0.8444\n",
      "Epoch 51/100\n",
      "0s - loss: 0.4074 - acc: 0.8345 - val_loss: 0.3744 - val_acc: 0.8000\n",
      "Epoch 52/100\n",
      "0s - loss: 0.4091 - acc: 0.8298 - val_loss: 0.3049 - val_acc: 0.8889\n",
      "Epoch 53/100\n",
      "0s - loss: 0.4087 - acc: 0.8381 - val_loss: 0.3372 - val_acc: 0.8889\n",
      "Epoch 54/100\n",
      "0s - loss: 0.4069 - acc: 0.8357 - val_loss: 0.3249 - val_acc: 0.8889\n",
      "Epoch 55/100\n",
      "0s - loss: 0.4103 - acc: 0.8333 - val_loss: 0.3172 - val_acc: 0.8889\n",
      "Epoch 56/100\n",
      "0s - loss: 0.4038 - acc: 0.8322 - val_loss: 0.3406 - val_acc: 0.8889\n",
      "Epoch 57/100\n",
      "0s - loss: 0.4030 - acc: 0.8369 - val_loss: 0.3233 - val_acc: 0.8889\n",
      "Epoch 58/100\n",
      "0s - loss: 0.4072 - acc: 0.8322 - val_loss: 0.3165 - val_acc: 0.8889\n",
      "Epoch 59/100\n",
      "0s - loss: 0.4047 - acc: 0.8310 - val_loss: 0.3131 - val_acc: 0.8889\n",
      "Epoch 60/100\n",
      "0s - loss: 0.4004 - acc: 0.8345 - val_loss: 0.3546 - val_acc: 0.8444\n",
      "Epoch 61/100\n",
      "0s - loss: 0.4046 - acc: 0.8345 - val_loss: 0.3635 - val_acc: 0.8667\n",
      "Epoch 62/100\n",
      "0s - loss: 0.4025 - acc: 0.8381 - val_loss: 0.3418 - val_acc: 0.8444\n",
      "Epoch 63/100\n",
      "0s - loss: 0.4010 - acc: 0.8310 - val_loss: 0.3672 - val_acc: 0.8889\n",
      "Epoch 64/100\n",
      "0s - loss: 0.4036 - acc: 0.8333 - val_loss: 0.3312 - val_acc: 0.8889\n",
      "Epoch 65/100\n",
      "0s - loss: 0.4004 - acc: 0.8381 - val_loss: 0.3370 - val_acc: 0.8889\n",
      "Epoch 66/100\n",
      "0s - loss: 0.4025 - acc: 0.8357 - val_loss: 0.3291 - val_acc: 0.8889\n",
      "Epoch 67/100\n",
      "0s - loss: 0.4021 - acc: 0.8310 - val_loss: 0.3148 - val_acc: 0.8889\n",
      "Epoch 68/100\n",
      "0s - loss: 0.4007 - acc: 0.8392 - val_loss: 0.3216 - val_acc: 0.8889\n",
      "Epoch 69/100\n",
      "0s - loss: 0.3984 - acc: 0.8357 - val_loss: 0.3614 - val_acc: 0.8889\n",
      "Epoch 70/100\n",
      "0s - loss: 0.4002 - acc: 0.8310 - val_loss: 0.3333 - val_acc: 0.8444\n",
      "Epoch 71/100\n",
      "0s - loss: 0.4036 - acc: 0.8310 - val_loss: 0.3081 - val_acc: 0.8889\n",
      "Epoch 72/100\n",
      "0s - loss: 0.4012 - acc: 0.8369 - val_loss: 0.3214 - val_acc: 0.8889\n",
      "Epoch 73/100\n",
      "0s - loss: 0.3968 - acc: 0.8357 - val_loss: 0.3128 - val_acc: 0.8889\n",
      "Epoch 74/100\n",
      "0s - loss: 0.3983 - acc: 0.8369 - val_loss: 0.3306 - val_acc: 0.8889\n",
      "Epoch 75/100\n",
      "0s - loss: 0.4017 - acc: 0.8345 - val_loss: 0.3248 - val_acc: 0.8889\n",
      "Epoch 76/100\n",
      "0s - loss: 0.3961 - acc: 0.8357 - val_loss: 0.3170 - val_acc: 0.8889\n",
      "Epoch 77/100\n",
      "0s - loss: 0.3976 - acc: 0.8345 - val_loss: 0.3175 - val_acc: 0.8889\n",
      "Epoch 78/100\n",
      "0s - loss: 0.3946 - acc: 0.8381 - val_loss: 0.3237 - val_acc: 0.8889\n",
      "Epoch 79/100\n",
      "0s - loss: 0.3949 - acc: 0.8333 - val_loss: 0.3086 - val_acc: 0.8889\n",
      "Epoch 80/100\n",
      "0s - loss: 0.3942 - acc: 0.8333 - val_loss: 0.3347 - val_acc: 0.8889\n",
      "Epoch 81/100\n",
      "0s - loss: 0.3949 - acc: 0.8345 - val_loss: 0.3257 - val_acc: 0.8889\n",
      "Epoch 82/100\n",
      "0s - loss: 0.3974 - acc: 0.8298 - val_loss: 0.3142 - val_acc: 0.8889\n",
      "Epoch 83/100\n",
      "0s - loss: 0.3964 - acc: 0.8369 - val_loss: 0.3097 - val_acc: 0.8889\n",
      "Epoch 84/100\n",
      "0s - loss: 0.3939 - acc: 0.8416 - val_loss: 0.3324 - val_acc: 0.8889\n",
      "Epoch 85/100\n",
      "0s - loss: 0.3923 - acc: 0.8416 - val_loss: 0.3235 - val_acc: 0.8889\n",
      "Epoch 86/100\n",
      "0s - loss: 0.3949 - acc: 0.8369 - val_loss: 0.3081 - val_acc: 0.8889\n",
      "Epoch 87/100\n",
      "0s - loss: 0.3930 - acc: 0.8369 - val_loss: 0.3217 - val_acc: 0.8889\n",
      "Epoch 88/100\n",
      "0s - loss: 0.3903 - acc: 0.8392 - val_loss: 0.3158 - val_acc: 0.8889\n",
      "Epoch 89/100\n",
      "0s - loss: 0.3984 - acc: 0.8381 - val_loss: 0.3002 - val_acc: 0.8889\n",
      "Epoch 90/100\n",
      "0s - loss: 0.3929 - acc: 0.8333 - val_loss: 0.3188 - val_acc: 0.8889\n",
      "Epoch 91/100\n",
      "0s - loss: 0.3959 - acc: 0.8369 - val_loss: 0.3144 - val_acc: 0.8889\n",
      "Epoch 92/100\n",
      "0s - loss: 0.3919 - acc: 0.8404 - val_loss: 0.3113 - val_acc: 0.8889\n",
      "Epoch 93/100\n",
      "0s - loss: 0.3899 - acc: 0.8392 - val_loss: 0.3162 - val_acc: 0.8889\n",
      "Epoch 94/100\n",
      "0s - loss: 0.3903 - acc: 0.8428 - val_loss: 0.3144 - val_acc: 0.8889\n",
      "Epoch 95/100\n",
      "0s - loss: 0.3882 - acc: 0.8392 - val_loss: 0.3265 - val_acc: 0.8889\n",
      "Epoch 96/100\n",
      "0s - loss: 0.3889 - acc: 0.8369 - val_loss: 0.3059 - val_acc: 0.8889\n",
      "Epoch 97/100\n",
      "0s - loss: 0.3946 - acc: 0.8381 - val_loss: 0.3220 - val_acc: 0.8889\n",
      "Epoch 98/100\n",
      "0s - loss: 0.3932 - acc: 0.8369 - val_loss: 0.3089 - val_acc: 0.8889\n",
      "Epoch 99/100\n",
      "0s - loss: 0.3913 - acc: 0.8392 - val_loss: 0.3223 - val_acc: 0.8889\n",
      "Epoch 100/100\n",
      "0s - loss: 0.3894 - acc: 0.8381 - val_loss: 0.3316 - val_acc: 0.8889\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "train_features = df.values[:,1:]\n",
    "train_labels = df.values[:,0]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=40, input_dim=7, kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dropout(rate=0.05))\n",
    "model.add(Dense(units=20, kernel_initializer='uniform', activation='relu'))\n",
    "# model.add(Dropout(rate=0.05))\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(x=train_reduced, \\\n",
    "                          y=train_labels, \\\n",
    "                          validation_split=0.05, \\\n",
    "                          epochs=100, \\\n",
    "                          batch_size=20, verbose=2)\n",
    "\n",
    "def show_train_history(train_history, train, validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "# show_train_history(train_history, 'acc', 'val_acc')\n",
    "# show_train_history(train_history, 'loss', 'val_loss')\n",
    "\n",
    "\n",
    "pred = model.predict_classes(test_reduced, verbose=2)\n",
    "# pred.ravel()\n",
    "result = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':pred.ravel().astype(np.int32)})\n",
    "result\n",
    "result.to_csv(\"/root/lab/27py/ipynb/titanic/data/reducing_feature_keras_mlp_predictions.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC - ROC :  0.963642028569\n",
      "0.970819304153\n",
      "[['Fare' '0.193716120246']\n",
      " ['Age' '0.183193126479']\n",
      " ['Title_Mr' '0.0998415726802']\n",
      " ['Sex_male' '0.0927853900816']\n",
      " ['Sex_female' '0.0856580216297']\n",
      " ['GangSize' '0.0561898386098']\n",
      " ['Pclass_3' '0.0436236723688']\n",
      " ['SibSp' '0.0325286020794']\n",
      " ['Title_Mrs' '0.0235111416883']\n",
      " ['Cabin_Yes' '0.0230446939994']\n",
      " ['Cabin_No' '0.0223906062307']\n",
      " ['Title_Miss' '0.0220596685196']\n",
      " ['Parch' '0.0181197028149']\n",
      " ['Pclass_1' '0.0175132404427']\n",
      " ['Pclass_2' '0.0146811076123']\n",
      " ['Embarked_S' '0.0140480137008']\n",
      " ['Embarked_C' '0.0120173952105']\n",
      " ['Title_Master' '0.00938227358821']\n",
      " ['Embarked_Q' '0.00863140870718']\n",
      " ['Physical_Child' '0.00821091095756']\n",
      " ['Physical_Adult' '0.00812110372944']\n",
      " ['Title_Officer' '0.00571273398096']\n",
      " ['Physical_Old_Man' '0.0033356098286']\n",
      " ['Class_Noble' '0.000580193355821']\n",
      " ['Title_Royalty' '0.000557368510939']\n",
      " ['Class_Civilian' '0.000546482947509']]\n",
      "('RMSE:', 0.17082358106351275)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 25 columns):\n",
      "Age                 418 non-null float64\n",
      "SibSp               418 non-null float64\n",
      "Parch               418 non-null float64\n",
      "Fare                418 non-null float64\n",
      "Physical_Adult      418 non-null uint8\n",
      "Physical_Child      418 non-null uint8\n",
      "Physical_Old_Man    418 non-null uint8\n",
      "Class_Civilian      418 non-null uint8\n",
      "Class_Noble         418 non-null uint8\n",
      "Title_Master        418 non-null uint8\n",
      "Title_Miss          418 non-null uint8\n",
      "Title_Mr            418 non-null uint8\n",
      "Title_Mrs           418 non-null uint8\n",
      "Title_Officer       418 non-null uint8\n",
      "Title_Royalty       418 non-null uint8\n",
      "Cabin_No            418 non-null uint8\n",
      "Cabin_Yes           418 non-null uint8\n",
      "Embarked_C          418 non-null uint8\n",
      "Embarked_Q          418 non-null uint8\n",
      "Embarked_S          418 non-null uint8\n",
      "Sex_female          418 non-null uint8\n",
      "Sex_male            418 non-null uint8\n",
      "Pclass_1            418 non-null uint8\n",
      "Pclass_2            418 non-null uint8\n",
      "Pclass_3            418 non-null uint8\n",
      "dtypes: float64(4), uint8(21)\n",
      "memory usage: 21.7 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "rf_df = df.copy()\n",
    "train_features = rf_df.values[:,1:]\n",
    "train_labels = rf_df.values[:,0]\n",
    "train_features_df = rf_df.loc[:, rf_df.columns != 'Survived']\n",
    "\n",
    "train_features_df['GangSize'] = 1\n",
    "train_features_df['GangSize'] = train_features_df['GangSize']+train_features_df['Parch']+\\\n",
    "                                train_features_df['SibSp']\n",
    "\n",
    "# Using feature_importances_ check and pick\n",
    "# train_features_df = train_features_df[['Fare','Age', 'Title_Mr', 'Sex_male', 'Sex_female',\\\n",
    "#                                       'GangSize', 'Pclass_3', 'SibSp']]\n",
    "features_forest = train_features_df.values\n",
    "target = df.Survived.values\n",
    "\n",
    "\n",
    "# # Tuning hyper-parameters\n",
    "# sample_leaf_options = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "# min_samples_split =[2,4,16,32,64,128]\n",
    "\n",
    "\n",
    "# for leaf_size in sample_leaf_options :\n",
    "\n",
    "#     forest = RandomForestClassifier(max_depth=16,n_estimators = 600, min_samples_split=2, \\\n",
    "#                                     random_state = 1, max_features=leaf_size, min_samples_leaf=1,\\\n",
    "#                                    oob_score = True)\n",
    "#     my_forest = forest.fit(features_forest, target)\n",
    "#     print \"AUC - ROC : \", roc_auc_score(target,my_forest.predict(features_forest))\n",
    "    \n",
    "forest = RandomForestClassifier(max_depth=16,n_estimators = 600, min_samples_split=2, \\\n",
    "                                    random_state = 1, max_features='sqrt', min_samples_leaf=1,\\\n",
    "                                   oob_score = True)\n",
    "my_forest = forest.fit(features_forest, target)\n",
    "print \"AUC - ROC : \", roc_auc_score(target,my_forest.predict(features_forest))\n",
    "\n",
    "print(my_forest.score(features_forest, target))\n",
    "\n",
    "# print(train_features_df.columns.values)\n",
    "# print(my_forest.feature_importances_)\n",
    "a = train_features_df.columns.values\n",
    "b = my_forest.feature_importances_\n",
    "# print(np.array(list(zip(a,b))))\n",
    "\n",
    "pair = np.array(list(zip(a,b)))\n",
    "print(pair[pair[:,1].argsort(kind='mergesort')[::-1][:30]])\n",
    "\n",
    "rf_df[\"eval_forest\"] = my_forest.predict(features_forest)\n",
    "\n",
    "rmse_tree = np.sqrt(mean_squared_error(rf_df[\"Survived\"], rf_df[\"eval_forest\"]))\n",
    "print(\"RMSE:\", rmse_tree)\n",
    "\n",
    "\n",
    "test_features_df = df_test.copy()\n",
    "test_features_df.info()\n",
    "test_features_df['GangSize'] = 1\n",
    "test_features_df['GangSize'] = test_features_df['GangSize']+test_features_df['Parch']+\\\n",
    "                                test_features_df['SibSp']\n",
    "    \n",
    "# test_features_df = test_features_df[['Fare','Age', 'Title_Mr', 'Sex_male', 'Sex_female',\\\n",
    "#                                       'GangSize', 'Pclass_3', 'SibSp']]\n",
    "\n",
    "rf_prediction = my_forest.predict(test_features_df.values)\n",
    "\n",
    "rf_solution = pd.DataFrame({'PassengerId':data_test['PassengerId'].as_matrix(), 'Survived':rf_prediction.ravel().astype(np.int32)})\n",
    "\n",
    "result.to_csv(\"/root/lab/27py/ipynb/titanic/data/reducing_feature_random_forest_predictions.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
